{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "71Sw-w76MX_J",
    "outputId": "867a377b-0fd9-4470-bb5a-f5d2ea8e7108"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "y6No8FCvMX_N",
    "outputId": "b5908cd2-47f5-42d1-c972-ca7fb24adb06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n"
     ]
    }
   ],
   "source": [
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n",
    "    # 784 columns per row\n",
    "    x_train = x_train.reshape(60000, 784)\n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "(X_train, y_train,X_test, y_test)=load_data()\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Q_v0ZORMX_S"
   },
   "outputs": [],
   "source": [
    "def adam_optimizer():\n",
    "    return Adam(lr=0.0002, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "colab_type": "code",
    "id": "A6z2xBQnMX_U",
    "outputId": "e99e5e42-8f9b-47a4-c29a-9a631e7aef91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               12928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 784)               803600    \n",
      "=================================================================\n",
      "Total params: 1,506,448\n",
      "Trainable params: 1,506,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_generator():\n",
    "    adam = adam_optimizer()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=100))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dense(256))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1024))\n",
    "    model.add(LeakyReLU(.2))\n",
    "    model.add(Dense(784, activation=\"sigmoid\"))\n",
    "    \n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=adam)\n",
    "    \n",
    "    return model\n",
    "g=get_generator()\n",
    "g.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "id": "BvQEvCsSMX_Y",
    "outputId": "d58fd65f-3c3f-474b-ce92-87aff1233fb3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 1,460,225\n",
      "Trainable params: 1,460,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_discriminator():\n",
    "    discriminator=Sequential()\n",
    "    discriminator.add(Dense(units=1024,input_dim=784))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    \n",
    "    discriminator.add(Dense(units=512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "       \n",
    "    discriminator.add(Dense(units=256))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    discriminator.add(Dense(units=1, activation='sigmoid'))\n",
    "    \n",
    "    discriminator.compile(loss='binary_crossentropy', optimizer=adam_optimizer())\n",
    "    return discriminator\n",
    "d =create_discriminator()\n",
    "d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "pfkMfymjMX_a",
    "outputId": "7270259a-21bb-4bab-a5db-671f44e63721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 784)               1506448   \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 1460225   \n",
      "=================================================================\n",
      "Total params: 2,966,673\n",
      "Trainable params: 1,506,448\n",
      "Non-trainable params: 1,460,225\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_gan(discriminator, generator):\n",
    "    discriminator.trainable=False\n",
    "    gan_input = Input(shape=(100,))\n",
    "    x = generator(gan_input)\n",
    "    gan_output= discriminator(x)\n",
    "    gan= Model(inputs=gan_input, outputs=gan_output)\n",
    "    gan.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "    return gan\n",
    "gan=create_gan(d,g)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Es4mpB7dMX_d"
   },
   "outputs": [],
   "source": [
    "def plot_generated_images(epoch, generator, examples=100, dim=(10,10), figsize=(10,10)):\n",
    "    noise= np.random.normal(loc=0, scale=1, size=[examples, 100])\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = generated_images.reshape(100,28,28)\n",
    "  #  plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "    #    plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i])\n",
    "     #   plt.axis('off')\n",
    "    #plt.tight_layout()\n",
    "    #plt.savefig('gan_generated_image %d.png' %epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "HdQFh5E-MX_f",
    "outputId": "f95f4408-b315-4bb9-b9a0-67dd3d9d4919"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n"
     ]
    }
   ],
   "source": [
    "def training(epochs=1, batch_size=128):\n",
    "    \n",
    "    #Loading the data\n",
    "    (X_train, y_train, X_test, y_test) = load_data()\n",
    "    batch_count = X_train.shape[0] / batch_size\n",
    "    \n",
    "    # Creating GAN\n",
    "    generator= get_generator()\n",
    "    discriminator= create_discriminator()\n",
    "    gan = create_gan(discriminator, generator)\n",
    "    \n",
    "    for e in range(1,epochs+1 ):\n",
    "        print(\"Epoch %d\" %e)\n",
    "        for _ in (range(batch_size)):\n",
    "        #generate  random noise as an input  to  initialize the  generator\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            \n",
    "            # Generate fake MNIST images from noised input\n",
    "            generated_images = generator.predict(noise)\n",
    "            \n",
    "            # Get a random set of  real images\n",
    "            image_batch =X_train[np.random.randint(low=0,high=X_train.shape[0],size=batch_size)]\n",
    "            \n",
    "            #Construct different batches of  real and fake data \n",
    "            X= np.concatenate([image_batch, generated_images])\n",
    "            \n",
    "            # Labels for generated and real data\n",
    "            y_dis=np.zeros(2*batch_size)\n",
    "            y_dis[:batch_size]=0.9\n",
    "            \n",
    "            #Pre train discriminator on  fake and real data  before starting the gan. \n",
    "            discriminator.trainable=True\n",
    "            discriminator.train_on_batch(X, y_dis)\n",
    "            \n",
    "            #Tricking the noised input of the Generator as real data\n",
    "            noise= np.random.normal(0,1, [batch_size, 100])\n",
    "            y_gen = np.ones(batch_size)\n",
    "            \n",
    "            # During the training of gan, \n",
    "            # the weights of discriminator should be fixed. \n",
    "            #We can enforce that by setting the trainable flag\n",
    "            discriminator.trainable=False\n",
    "            \n",
    "            #training  the GAN by alternating the training of the Discriminator \n",
    "            #and training the chained GAN model with Discriminator’s weights freezed.\n",
    "            gan.train_on_batch(noise, y_gen)\n",
    "            \n",
    "        if e == 1 or e % 20 == 0:\n",
    "            plt.figure()\n",
    "            plt.imshow(generated_images[0].reshape(28, 28))\n",
    "            plt.show()\n",
    "training(400,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-lj5MwdTMr-5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "GAN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
